{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['och',\n",
       " 'det',\n",
       " 'att',\n",
       " 'i',\n",
       " 'en',\n",
       " 'jag',\n",
       " 'hon',\n",
       " 'som',\n",
       " 'han',\n",
       " 'på',\n",
       " 'den',\n",
       " 'med',\n",
       " 'var',\n",
       " 'sig',\n",
       " 'för',\n",
       " 'så',\n",
       " 'till',\n",
       " 'är',\n",
       " 'men',\n",
       " 'ett',\n",
       " 'om',\n",
       " 'hade',\n",
       " 'de',\n",
       " 'av',\n",
       " 'icke',\n",
       " 'mig',\n",
       " 'du',\n",
       " 'henne',\n",
       " 'då',\n",
       " 'sin',\n",
       " 'nu',\n",
       " 'har',\n",
       " 'inte',\n",
       " 'hans',\n",
       " 'honom',\n",
       " 'skulle',\n",
       " 'hennes',\n",
       " 'där',\n",
       " 'min',\n",
       " 'man',\n",
       " 'ej',\n",
       " 'vid',\n",
       " 'kunde',\n",
       " 'något',\n",
       " 'från',\n",
       " 'ut',\n",
       " 'när',\n",
       " 'efter',\n",
       " 'upp',\n",
       " 'vi',\n",
       " 'dem',\n",
       " 'vara',\n",
       " 'vad',\n",
       " 'över',\n",
       " 'än',\n",
       " 'dig',\n",
       " 'kan',\n",
       " 'sina',\n",
       " 'här',\n",
       " 'ha',\n",
       " 'mot',\n",
       " 'alla',\n",
       " 'under',\n",
       " 'någon',\n",
       " 'eller',\n",
       " 'allt',\n",
       " 'mycket',\n",
       " 'sedan',\n",
       " 'ju',\n",
       " 'denna',\n",
       " 'själv',\n",
       " 'detta',\n",
       " 'åt',\n",
       " 'utan',\n",
       " 'varit',\n",
       " 'hur',\n",
       " 'ingen',\n",
       " 'mitt',\n",
       " 'ni',\n",
       " 'bli',\n",
       " 'blev',\n",
       " 'oss',\n",
       " 'din',\n",
       " 'dessa',\n",
       " 'några',\n",
       " 'deras',\n",
       " 'blir',\n",
       " 'mina',\n",
       " 'samma',\n",
       " 'vilken',\n",
       " 'er',\n",
       " 'sådan',\n",
       " 'vår',\n",
       " 'blivit',\n",
       " 'dess',\n",
       " 'inom',\n",
       " 'mellan',\n",
       " 'sådant',\n",
       " 'varför',\n",
       " 'varje',\n",
       " 'vilka',\n",
       " 'ditt',\n",
       " 'vem',\n",
       " 'vilket',\n",
       " 'sitta',\n",
       " 'sådana',\n",
       " 'vart',\n",
       " 'dina',\n",
       " 'vars',\n",
       " 'vårt',\n",
       " 'våra',\n",
       " 'ert',\n",
       " 'era',\n",
       " 'vilkas']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('swedish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries=nltk.corpus.cmudict.entries()\n",
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn \n",
    "wn.synsets('motorcar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts=[\"\"\"See what words occur near other words, which provides great insight into meaning and usage. For example, nouns after thick or look into, verbs before money, or any word near crack, believe, loud, or quickly. \n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-11-74ec82bbe864>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-74ec82bbe864>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for text in texts:\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for text in texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('See', 'VB'), ('what', 'WP'), ('words', 'NNS'), ('occur', 'VBP'), ('near', 'IN'), ('other', 'JJ'), ('words', 'NNS'), (',', ','), ('which', 'WDT'), ('provides', 'VBZ'), ('great', 'JJ'), ('insight', 'JJ'), ('into', 'IN'), ('meaning', 'NN'), ('and', 'CC'), ('usage', 'NN'), ('.', '.')]\n",
      "[('For', 'IN'), ('example', 'NN'), (',', ','), ('nouns', 'RB'), ('after', 'IN'), ('thick', 'NN'), ('or', 'CC'), ('look', 'NN'), ('into', 'IN'), (',', ','), ('verbs', 'FW'), ('before', 'IN'), ('money', 'NN'), (',', ','), ('or', 'CC'), ('any', 'DT'), ('word', 'NN'), ('near', 'IN'), ('crack', 'NN'), (',', ','), ('believe', 'VBP'), (',', ','), ('loud', 'JJ'), (',', ','), ('or', 'CC'), ('quickly', 'RB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    sentences=nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words=nltk.word_tokenize(sentence)\n",
    "        tagged=nltk.pos_tag(words)\n",
    "        print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Party', 'was', 'sooo', 'fun', ':D', '#superfun']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "text='The Party was sooo fun :D #superfun'\n",
    "twtkn=TweetTokenizer()\n",
    "twtkn.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happi'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "StemmerPorter=PorterStemmer()\n",
    "StemmerPorter.stem('happiness')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'language'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-750c5ec6c50d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'french'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'language'"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "SnowballStemmer=SnowballStemmer()\n",
    "SnowballStemmer.stem('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmerLan=LancasterStemmer()\n",
    "stemmerLan.stem('working')\n",
    "stemmerLan.stem('happiness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerLan.stem('working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'archaeolog'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerLan.stem('archaeological')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dark'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerLan.stem('darkness')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stem() missing 1 required positional argument: 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a7990f4d41a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'darkness'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: stem() missing 1 required positional argument: 'word'"
     ]
    }
   ],
   "source": [
    "PorterStemmer.stem('darkness')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dark'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StemmerPorter.stem('darkness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ugli'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StemmerPorter.stem('ugly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StemmerLan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-70c5fcb8849a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mStemmerLan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ugly'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'StemmerLan' is not defined"
     ]
    }
   ],
   "source": [
    "StemmerLan.stem('ugly')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stemerLan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-503e7ac0b891>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstemerLan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ugly'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stemerLan' is not defined"
     ]
    }
   ],
   "source": [
    "stemerLan.stem('ugly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ug'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmerLan.stem('ugly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return{'last_letter':word[-1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_names=([(name,'male') for name in names.words('male.txt')])+([(name,'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets=[(gender_features(n),gender) for (n,gender) in labeled_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set,test_set=featuresets[500:],featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier=nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('adithya'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier,test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat wa chase a mous\n"
     ]
    }
   ],
   "source": [
    "example=\"A cat was chasing a mouse\"\n",
    "example=[stemmer.stem(token) for token in example.split(\" \")]\n",
    "print(\" \".join(example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waisal serevi (born 1968) is a former fijian rugbi union footbal and coach. A member of the world rugbi hall of fame, he is wide consid to be the greatest rugbi seven player in the histori of the game. In the 15-man game, he play for fiji 39 time between 1989 and 2003, score 376 point and repres hi countri in the 1991, 1999, and 2003 rugbi world cups. He also play profession for the mitsubishi, leicester, stade montois, stade bordelai and stain rugbi teams.\n"
     ]
    }
   ],
   "source": [
    "example=\"Waisale Serevi (born 1968) is a former Fijian rugby union footballer and coach. A member of the World Rugby Hall of Fame, he is widely considered to be the greatest rugby sevens player in the history of the game. In the 15-man game, he played for Fiji 39 times between 1989 and 2003, scoring 376 points and representing his country in the 1991, 1999, and 2003 Rugby World Cups. He also played professionally for the Mitsubishi, Leicester, Stade Montois, Stade Bordelais and Staines rugby teams.\"\n",
    "example=[stemmer.stem(token) for token in example.split(\" \")]\n",
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat wa chasing a mice. There wa a cactus around a corner\n"
     ]
    }
   ],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "example=\"A cat was chasing a mice. There was a cacti around a corner\"\n",
    "example=[lemmatizer.lemmatize(token) for token in example.split(\" \")]\n",
    "print(\" \".join(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize('better',pos='a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "vect=CountVectorizer(binary=True)\n",
    "corpus=[\"Tessaract is an optical recogniction engine\", \"optical character\"]\n",
    "vect.fit(corpus)\n",
    "print(vect.transform([\"tessaract is a optical recognition engine \"]).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.53404633  0.53404633  0.37997836  0.\n",
      "   0.53404633]]\n"
     ]
    }
   ],
   "source": [
    "vect=TfidfVectorizer(binary=False )\n",
    "corpus=[\"Tessaract is an optical recogniction engine\", \"optical character\"]\n",
    "vect.fit(corpus)\n",
    "print(vect.transform([\"tessaract is a optical recognition engine \"]).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity=cosine_similarity(vect.transform([\"\"\"Summer is a charming flirt. Easy going and casual. Summer doesnt huff and puff to win our affection. It has us at \"Hello\". Winter broods like the tortured protagonist of big fat russian novel. It is daunting and dramatic, burning with a slow intensity.The seasons reputation precedes itself, and often, not in a good way. It has a way of whittling down everything to its bare bones. Even relationships not attuned to its ebbs and flows can fray. At a dinner conversation I once attended, I listened in bemusement as a recent divorcee, made the case that it was the Scandinavian frost that had cooled his exwifes ardour. How original\"\"\"]).toarray(),\n",
    "                             vect.transform([\"\"\"One of the finer books i read this year was John Kaag's Hiking With Nietzsche, in which Kaag, a professor of philosophy, rekindles his passion for the German thinker while tracing picturesque hiking trails in the mountains of Switzerland. It's a near-precise rendering of the travelogue as a self-help book. A young Kaag was an avowed Nietzsche acolyte but given the ravages of responsibilities and adulthood, the writer put his affinity to test by undertaking physically enduring hikes through the Alps, revisiting haunts that the philosopher escaped to, in search of solitude and salve. The journey's demands, coupled with his own innre turmoil, are catnip for anybody feeling at cross purposes with their own life.\"\"\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
